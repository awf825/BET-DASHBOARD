{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9423c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: pandas in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: python-dateutil in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: lxml in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (6.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from python-dateutil) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nbainjuries in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: PyPDF2<4.0,>=3.0.1 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from nbainjuries) (3.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.9.3 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from nbainjuries) (3.13.3)\n",
      "Requirement already satisfied: jpype1<1.6.0,>=1.5.2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from nbainjuries) (1.5.2)\n",
      "Requirement already satisfied: pandas<3.0,>=2.2.3 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from nbainjuries) (2.3.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.32.3 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from nbainjuries) (2.32.5)\n",
      "Requirement already satisfied: tabula-py<3.0,>=2.9.0 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from nbainjuries) (2.10.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.9.3->nbainjuries) (1.22.0)\n",
      "Requirement already satisfied: packaging in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from jpype1<1.6.0,>=1.5.2->nbainjuries) (25.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas<3.0,>=2.2.3->nbainjuries) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas<3.0,>=2.2.3->nbainjuries) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas<3.0,>=2.2.3->nbainjuries) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from pandas<3.0,>=2.2.3->nbainjuries) (2025.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests<3.0,>=2.32.3->nbainjuries) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests<3.0,>=2.32.3->nbainjuries) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests<3.0,>=2.32.3->nbainjuries) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from requests<3.0,>=2.32.3->nbainjuries) (2025.11.12)\n",
      "Requirement already satisfied: distro in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from tabula-py<3.0,>=2.9.0->nbainjuries) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp<4.0,>=3.9.3->nbainjuries) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=2.2.3->nbainjuries) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: html5lib in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from html5lib) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Users/aidenflynn/BET-DASHBOARD/flask-dashboard/venv/lib/python3.11/site-packages (from html5lib) (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pandas python-dateutil tqdm lxml\n",
    "!pip install nbainjuries  # from the mxufc29 project\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b76ebcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "NBA_LID, NBA_SPID = 5, 5\n",
    "\n",
    "SBR_ENDPOINTS = [\n",
    "    \"https://www.oddstrader.com/odds-v2/odds-v2-service\",\n",
    "    \"https://ms.production-us-east-1.bookmakersreview.com/ms-odds-v2/odds-v2-service\",\n",
    "]\n",
    "\n",
    "def sbr_gql(query: str, variables: dict | None = None, endpoint: str | None = None, timeout=30, debug=False):\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"variables\": variables or {},\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/123.0.0.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Origin\": \"https://www.sportsbookreview.com\",\n",
    "        \"Referer\": \"https://www.sportsbookreview.com/\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    "\n",
    "    endpoints = [endpoint] if endpoint else SBR_ENDPOINTS\n",
    "    last_err = None\n",
    "\n",
    "    for url in endpoints:\n",
    "        try:\n",
    "            r = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "            if r.status_code != 200:\n",
    "                raise RuntimeError(f\"HTTP {r.status_code} from {url}\\nResponse: {(r.text or '')[:800]}\")\n",
    "            out = r.json()\n",
    "            if \"errors\" in out:\n",
    "                if debug:\n",
    "                    print(\"DEBUG payload sent:\\n\", json.dumps(payload, indent=2)[:2000])\n",
    "                raise RuntimeError(out[\"errors\"])\n",
    "            return out[\"data\"]\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.25 + random.random() * 0.25)\n",
    "\n",
    "    raise last_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09954ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from lxml import html as lh\n",
    "\n",
    "SBR_UA = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "def matchup_ids_on_date(date_yyyy_mm_dd: str) -> list[int]:\n",
    "    url = f\"https://www.sportsbookreview.com/betting-odds/nba-basketball/?date={date_yyyy_mm_dd}\"\n",
    "    r = requests.get(url, headers=SBR_UA, timeout=30)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    doc = lh.fromstring(r.text)\n",
    "    hrefs = doc.xpath(\"//a/@href\")\n",
    "\n",
    "    ids = set()\n",
    "    # match both matchup + line-history links (both carry the same numeric id)\n",
    "    for h in hrefs:\n",
    "        m = re.search(r\"/nba-basketball/(?:line-history|matchup)/(\\d+)/\", h)\n",
    "        if m:\n",
    "            ids.add(int(m.group(1)))\n",
    "\n",
    "    return sorted(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46442ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_line_history_html(matchup_id: int) -> str:\n",
    "    url = f\"https://www.sportsbookreview.com/betting-odds/nba-basketball/line-history/{matchup_id}/\"\n",
    "    r = requests.get(url, headers=SBR_UA, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def fetch_matchup_html(matchup_id: int) -> str:\n",
    "    url = f\"https://www.sportsbookreview.com/scores/nba-basketball/matchup/{matchup_id}/\"\n",
    "    r = requests.get(url, headers=SBR_UA, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "import json, re\n",
    "\n",
    "def extract_next_data(html: str) -> dict | None:\n",
    "    # Correct pattern: id=\"__NEXT_DATA__\"\n",
    "    m = re.search(r'<script[^>]+id=\"__NEXT_DATA__\"[^>]*>\\s*(\\{.*?\\})\\s*</script>', html, re.S)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(m.group(1))\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def walk_json(x):\n",
    "    if isinstance(x, dict):\n",
    "        yield x\n",
    "        for v in x.values():\n",
    "            yield from walk_json(v)\n",
    "    elif isinstance(x, list):\n",
    "        for it in x:\n",
    "            yield from walk_json(it)\n",
    "\n",
    "def find_line_history_records(next_data: dict) -> list[dict]:\n",
    "    records = []\n",
    "    for obj in walk_json(next_data):\n",
    "        if not isinstance(obj, dict):\n",
    "            continue\n",
    "        keys = {str(k).lower() for k in obj.keys()}\n",
    "\n",
    "        has_time = any(k in keys for k in (\"ts\",\"time\",\"timestamp\",\"date\",\"createdat\",\"updatedat\")) or any(\"time\" in k or \"date\" in k for k in keys)\n",
    "        has_spread = any(k in keys for k in (\"spread\",\"hcap\",\"handicap\",\"line\",\"points\")) or any(\"spread\" in k or \"hcap\" in k for k in keys)\n",
    "        has_book = any(k in keys for k in (\"book\",\"sportsbook\",\"sb\",\"sportsbookname\")) or any(\"book\" in k or \"sportsbook\" in k for k in keys)\n",
    "\n",
    "        if has_time and has_spread and has_book:\n",
    "            records.append(obj)\n",
    "\n",
    "    return records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc354872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "SBR_UA = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "def fetch_line_history_html(eid: int) -> str:\n",
    "    url = f\"https://www.sportsbookreview.com/betting-odds/nba-basketball/line-history/{eid}/\"\n",
    "    r = requests.get(url, headers=SBR_UA, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def extract_next_data(html: str) -> dict:\n",
    "    m = re.search(r'<script[^>]+id=\"__NEXT_DATA__\"[^>]*>\\s*(\\{.*?\\})\\s*</script>', html, re.S)\n",
    "    if not m:\n",
    "        raise RuntimeError(\"No __NEXT_DATA__ script found\")\n",
    "    return json.loads(m.group(1))\n",
    "\n",
    "def parse_fanduel_line_history(matchup_id: int) -> dict:\n",
    "    \"\"\"\n",
    "    Return the raw Next.js pageProps dict for inspection.\n",
    "    We'll extract the actual history list from it.\n",
    "    \"\"\"\n",
    "    html = fetch_line_history_html(matchup_id)\n",
    "    nd = extract_next_data(html)\n",
    "    props = nd.get(\"props\", {}).get(\"pageProps\", {})\n",
    "    return props\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee47e865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pageProps keys: ['regionCode', 'countryCode', 'lineHistoryModel', 'league', 'breadcrumbListObject', 'navVM', 'region']\n",
      "HITS (first 80):\n",
      "lineHistoryModel\n",
      "lineHistoryModel.lineHistory\n",
      "lineHistoryModel.lineHistory.gameView.consensus.homeMoneyLinePickPercent\n",
      "lineHistoryModel.lineHistory.gameView.consensus.awayMoneyLinePickPercent\n",
      "lineHistoryModel.lineHistory.oddsViews\n",
      "lineHistoryModel.lineHistory.oddsViews[0].sportsbook\n",
      "lineHistoryModel.lineHistory.oddsViews[0].sportsbookId\n",
      "lineHistoryModel.lineHistory.oddsViews[0].openingLine\n",
      "lineHistoryModel.lineHistory.oddsViews[0].currentLine\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[0].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[0].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[0].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[1].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[1].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[1].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[2].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[2].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[2].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[3].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[3].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[3].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[4].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[4].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].moneyLineHistory[4].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[0].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[0].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[0].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[1].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[1].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[1].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[2].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[2].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[2].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[3].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[3].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].spreadHistory[3].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[0].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[0].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[0].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[1].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[1].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[1].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[2].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[2].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[2].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[3].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[3].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[3].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[4].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[4].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[4].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[5].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[5].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[5].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[6].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[6].overOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[0].totalHistory[6].underOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].sportsbook\n",
      "lineHistoryModel.lineHistory.oddsViews[1].sportsbookId\n",
      "lineHistoryModel.lineHistory.oddsViews[1].openingLine\n",
      "lineHistoryModel.lineHistory.oddsViews[1].currentLine\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[0].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[0].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[0].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[1].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[1].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[1].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[2].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[2].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[2].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[3].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[3].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[3].awayOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[4].oddsDate\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[4].homeOdds\n",
      "lineHistoryModel.lineHistory.oddsViews[1].moneyLineHistory[4].awayOdds\n"
     ]
    }
   ],
   "source": [
    "mid = 250647\n",
    "props = parse_fanduel_line_history(mid)\n",
    "print(\"pageProps keys:\", list(props.keys())[:100])\n",
    "\n",
    "def find_keys(obj, path=\"\"):\n",
    "    out = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k,v in obj.items():\n",
    "            p = f\"{path}.{k}\" if path else k\n",
    "            kl = str(k).lower()\n",
    "            if any(x in kl for x in [\"history\",\"line\",\"odds\",\"book\",\"sportsbook\",\"fanduel\"]):\n",
    "                out.append(p)\n",
    "            out.extend(find_keys(v, p))\n",
    "    elif isinstance(obj, list):\n",
    "        for i,v in enumerate(obj[:50]):  # cap\n",
    "            p = f\"{path}[{i}]\"\n",
    "            out.extend(find_keys(v, p))\n",
    "    return out\n",
    "\n",
    "hits = find_keys(props)\n",
    "print(\"HITS (first 80):\")\n",
    "print(\"\\n\".join(hits[:80]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b54909bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def parse_tipoff_from_linehistory_model(props: dict) -> datetime | None:\n",
    "    \"\"\"\n",
    "    Try common locations for scheduled start. We'll expand if needed.\n",
    "    \"\"\"\n",
    "    lh = props.get(\"lineHistoryModel\", {}).get(\"lineHistory\", {})\n",
    "    gv = lh.get(\"gameView\", {}) or {}\n",
    "    # Common fields you may find: startDate, gameDate, eventDate, etc.\n",
    "    for k in [\"gameDate\", \"startDate\", \"startTime\", \"eventDate\", \"date\"]:\n",
    "        v = gv.get(k)\n",
    "        if v:\n",
    "            dt = pd.to_datetime(v, utc=True, errors=\"coerce\")\n",
    "            if not pd.isna(dt):\n",
    "                return dt.to_pydatetime()\n",
    "    return None\n",
    "\n",
    "def fanduel_spread_history_from_props(props: dict) -> pd.DataFrame:\n",
    "    odds_views = (\n",
    "        props.get(\"lineHistoryModel\", {})\n",
    "             .get(\"lineHistory\", {})\n",
    "             .get(\"oddsViews\", [])\n",
    "    )\n",
    "    if not isinstance(odds_views, list) or not odds_views:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # find FanDuel\n",
    "    fd = None\n",
    "    for ov in odds_views:\n",
    "        sb = str(ov.get(\"sportsbook\") or \"\").strip().lower()\n",
    "        if sb == \"fanduel\":\n",
    "            fd = ov\n",
    "            break\n",
    "    if fd is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    hist = fd.get(\"spreadHistory\") or []\n",
    "    if not isinstance(hist, list) or not hist:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(hist)\n",
    "\n",
    "    # normalize time + spreads\n",
    "    # oddsDate appears to be an ISO string\n",
    "    df[\"ts\"] = pd.to_datetime(df.get(\"oddsDate\"), utc=True, errors=\"coerce\")\n",
    "    # homeSpread should exist (if not, we’ll infer later)\n",
    "    if \"homeSpread\" in df.columns:\n",
    "        df[\"home_spread\"] = pd.to_numeric(df[\"homeSpread\"], errors=\"coerce\")\n",
    "    elif \"spread\" in df.columns:\n",
    "        df[\"home_spread\"] = pd.to_numeric(df[\"spread\"], errors=\"coerce\")\n",
    "    else:\n",
    "        # fallback: you can inspect df.columns if this happens\n",
    "        df[\"home_spread\"] = pd.NA\n",
    "\n",
    "    df = df.dropna(subset=[\"ts\", \"home_spread\"]).sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "    # opening line (feature) from sportsbook node if present\n",
    "    opening = fd.get(\"openingLine\")\n",
    "    # openingLine may be a dict or direct number depending on SBR\n",
    "    if isinstance(opening, dict):\n",
    "        # common key names\n",
    "        for k in [\"homeSpread\", \"spread\", \"hcap\"]:\n",
    "            if k in opening:\n",
    "                opening = opening[k]\n",
    "                break\n",
    "    try:\n",
    "        opening = float(opening) if opening is not None else None\n",
    "    except Exception:\n",
    "        opening = None\n",
    "\n",
    "    df.attrs[\"opening_home_spread\"] = opening\n",
    "    df.attrs[\"sportsbookId\"] = fd.get(\"sportsbookId\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7ef5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_targets_from_fd_history(fd_df: pd.DataFrame, tipoff_utc: datetime) -> tuple[float|None, float|None, float|None, float|None]:\n",
    "    if fd_df is None or fd_df.empty:\n",
    "        return None, None, None, None\n",
    "\n",
    "    opening = fd_df.attrs.get(\"opening_home_spread\")\n",
    "    if opening is None:\n",
    "        # fall back: first pre-tip value as opening\n",
    "        opening = float(fd_df.iloc[0][\"home_spread\"])\n",
    "\n",
    "    pre = fd_df[fd_df[\"ts\"] < tipoff_utc].copy()\n",
    "    if pre.empty:\n",
    "        return None, None, None, None\n",
    "\n",
    "    pre = pre.sort_values(\"ts\")\n",
    "    closing = float(pre.iloc[-1][\"home_spread\"])\n",
    "\n",
    "    closing_diff = closing - float(opening)\n",
    "\n",
    "    best = float(pre[\"home_spread\"].max())   # best for home = higher spread\n",
    "    worst = float(pre[\"home_spread\"].min())  # worst for home = lower spread\n",
    "\n",
    "    max_move_for = best - float(opening)\n",
    "    max_move_away = float(opening) - worst\n",
    "\n",
    "    if max_move_for < 0: max_move_for = 0.0\n",
    "    if max_move_away < 0: max_move_away = 0.0\n",
    "\n",
    "    return float(opening), float(closing_diff), float(max_move_for), float(max_move_away)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "887c6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_matchup_pageprops(matchup_id: int) -> dict:\n",
    "    html = fetch_matchup_html(matchup_id)\n",
    "    nd = extract_next_data(html)\n",
    "    return nd.get(\"props\", {}).get(\"pageProps\", {})\n",
    "\n",
    "def tipoff_utc_from_matchup(matchup_id: int) -> datetime:\n",
    "    props = parse_matchup_pageprops(matchup_id)\n",
    "\n",
    "    # Search a few common fields\n",
    "    candidates = []\n",
    "    def walk(o):\n",
    "        if isinstance(o, dict):\n",
    "            for k,v in o.items():\n",
    "                kl = str(k).lower()\n",
    "                if any(x in kl for x in [\"start\", \"game\", \"tip\", \"date\", \"time\"]) and isinstance(v, (str,int,float)):\n",
    "                    candidates.append((k, v))\n",
    "                walk(v)\n",
    "        elif isinstance(o, list):\n",
    "            for it in o[:50]:\n",
    "                walk(it)\n",
    "\n",
    "    walk(props)\n",
    "\n",
    "    # Prefer ISO-like strings first\n",
    "    for k,v in candidates:\n",
    "        if isinstance(v, str) and (\"t\" in v.lower() and \":\" in v):\n",
    "            dt = pd.to_datetime(v, utc=True, errors=\"coerce\")\n",
    "            if not pd.isna(dt):\n",
    "                return dt.to_pydatetime()\n",
    "\n",
    "    # Next: epoch ms/sec\n",
    "    for k,v in candidates:\n",
    "        if isinstance(v, (int,float)) and v > 1e12:\n",
    "            return datetime.fromtimestamp(float(v)/1000.0, tz=timezone.utc)\n",
    "        if isinstance(v, (int,float)) and v > 1e9:\n",
    "            return datetime.fromtimestamp(float(v), tz=timezone.utc)\n",
    "\n",
    "    raise RuntimeError(f\"Could not find tipoff time in matchup pageProps for matchup_id={matchup_id}. Sample candidates={candidates[:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b7cbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_datetime_utc(x) -> datetime | None:\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    if isinstance(x, (int, float)) and x > 1e12:\n",
    "        # ms epoch\n",
    "        return datetime.fromtimestamp(float(x)/1000.0, tz=timezone.utc)\n",
    "    if isinstance(x, (int, float)) and x > 1e9:\n",
    "        # sec epoch\n",
    "        return datetime.fromtimestamp(float(x), tz=timezone.utc)\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    # Let pandas parse; assume UTC if no tz info\n",
    "    dt = pd.to_datetime(s, utc=True, errors=\"coerce\")\n",
    "    if pd.isna(dt):\n",
    "        return None\n",
    "    return dt.to_pydatetime()\n",
    "\n",
    "def normalize_line_history_df(raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = raw.copy()\n",
    "\n",
    "    # book column\n",
    "    book_col = None\n",
    "    for c in df.columns:\n",
    "        cl = str(c).lower()\n",
    "        if cl in (\"book\", \"sportsbook\", \"sports book\", \"sb\"):\n",
    "            book_col = c; break\n",
    "        if \"sportsbook\" in cl or \"book\" in cl:\n",
    "            book_col = c; break\n",
    "    if book_col is None:\n",
    "        # sometimes nested in JSON as sportsbook.name\n",
    "        # just keep going and let user see failure\n",
    "        raise RuntimeError(f\"Cannot find book column. Columns={list(df.columns)}\")\n",
    "\n",
    "    # time column\n",
    "    time_col = None\n",
    "    for c in df.columns:\n",
    "        cl = str(c).lower()\n",
    "        if cl in (\"time\", \"date\", \"timestamp\", \"ts\"):\n",
    "            time_col = c; break\n",
    "        if \"time\" in cl or \"date\" in cl:\n",
    "            time_col = c; break\n",
    "    if time_col is None:\n",
    "        raise RuntimeError(f\"Cannot find time column. Columns={list(df.columns)}\")\n",
    "\n",
    "    # spread column (home handicap)\n",
    "    spread_col = None\n",
    "    for c in df.columns:\n",
    "        cl = str(c).lower()\n",
    "        if cl in (\"spread\", \"hcap\", \"handicap\", \"line\"):\n",
    "            spread_col = c; break\n",
    "        if \"spread\" in cl or \"hcap\" in cl or \"handicap\" in cl:\n",
    "            spread_col = c; break\n",
    "    if spread_col is None:\n",
    "        raise RuntimeError(f\"Cannot find spread column. Columns={list(df.columns)}\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"book\": df[book_col].astype(str),\n",
    "        \"ts\": df[time_col].map(_to_datetime_utc),\n",
    "        \"home_spread\": pd.to_numeric(df[spread_col], errors=\"coerce\"),\n",
    "    })\n",
    "    out = out.dropna(subset=[\"book\", \"ts\", \"home_spread\"]).sort_values(\"ts\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa56c1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notable players (seeded): 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from lxml import html\n",
    "\n",
    "CBS_TOP100_URL = \"https://www.cbssports.com/nba/news/nba-top-100-players-2025-26-season/\"  # :contentReference[oaicite:8]{index=8}\n",
    "\n",
    "def fetch_cbs_top100_names() -> set[str]:\n",
    "    r = requests.get(CBS_TOP100_URL, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    tree = html.fromstring(r.text)\n",
    "    text = \" \".join(tree.xpath(\"//text()\"))\n",
    "    # CBS pages often include “No. 1: Nikola Jokic” patterns\n",
    "    names = set()\n",
    "    for m in re.finditer(r\"No\\.\\s*\\d+\\s*:\\s*([A-Z][a-zA-Z\\.\\-']+\\s+[A-Z][a-zA-Z\\.\\-']+)\", text):\n",
    "        names.add(m.group(1).strip())\n",
    "    # If this returns small due to layout changes, you can swap to a more specific XPath later.\n",
    "    return names\n",
    "\n",
    "NOTABLE_PLAYERS = fetch_cbs_top100_names()\n",
    "print(\"Notable players (seeded):\", len(NOTABLE_PLAYERS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c22e64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def matchup_pageprops(matchup_id: int) -> dict:\n",
    "    html = fetch_matchup_html(matchup_id)\n",
    "    nd = extract_next_data(html)\n",
    "    return nd.get(\"props\", {}).get(\"pageProps\", {})\n",
    "\n",
    "\n",
    "def _walk(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        yield obj\n",
    "        for v in obj.values():\n",
    "            yield from _walk(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for it in obj[:200]:  # cap recursion\n",
    "            yield from _walk(it)\n",
    "\n",
    "def _find_first_dict_with_keys(props: dict, required_keys: set[str]) -> dict | None:\n",
    "    req = {k.lower() for k in required_keys}\n",
    "    for d in _walk(props):\n",
    "        if isinstance(d, dict):\n",
    "            keys = {str(k).lower() for k in d.keys()}\n",
    "            if req.issubset(keys):\n",
    "                return d\n",
    "    return None\n",
    "\n",
    "def extract_home_away_teams(props: dict) -> tuple[str|None, str|None]:\n",
    "    \"\"\"\n",
    "    Try common shapes:\n",
    "    - props.game.homeTeam / awayTeam\n",
    "    - props.matchup.home / away\n",
    "    - participants with isHome flag\n",
    "    \"\"\"\n",
    "    # Try a \"game\" dict\n",
    "    game = props.get(\"game\") or props.get(\"matchup\") or props.get(\"event\")\n",
    "    if isinstance(game, dict):\n",
    "        for hk, ak in [(\"homeTeam\",\"awayTeam\"), (\"home\",\"away\")]:\n",
    "            h = game.get(hk); a = game.get(ak)\n",
    "            if isinstance(h, dict) and isinstance(a, dict):\n",
    "                hn = h.get(\"name\") or h.get(\"nam\") or h.get(\"fullName\")\n",
    "                an = a.get(\"name\") or a.get(\"nam\") or a.get(\"fullName\")\n",
    "                if hn and an:\n",
    "                    return str(hn), str(an)\n",
    "\n",
    "    # Search for participants\n",
    "    d = _find_first_dict_with_keys(props, {\"participants\"})\n",
    "    if d and isinstance(d.get(\"participants\"), list):\n",
    "        home = None; away = None\n",
    "        for p in d[\"participants\"]:\n",
    "            if not isinstance(p, dict): \n",
    "                continue\n",
    "            ih = p.get(\"ih\") or p.get(\"isHome\") or p.get(\"home\")\n",
    "            nm = None\n",
    "            src = p.get(\"source\") or p.get(\"team\") or p\n",
    "            if isinstance(src, dict):\n",
    "                nm = src.get(\"nam\") or src.get(\"name\") or src.get(\"fullName\")\n",
    "            if ih is True:\n",
    "                home = nm\n",
    "            elif ih is False:\n",
    "                away = nm\n",
    "        return (str(home) if home else None, str(away) if away else None)\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d17c1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_team_stats_features(props: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Returns columns like:\n",
    "      stat_pts_for_home, stat_pts_for_away, stat_pts_against_home, ...\n",
    "    using whatever the matchup page provides.\n",
    "    \"\"\"\n",
    "    # Find a list-like block that looks like team stats rows\n",
    "    # Common keys: \"teamStats\", \"teamStatistics\", \"statistics\", \"statRows\"\n",
    "    candidates = []\n",
    "    for d in _walk(props):\n",
    "        if isinstance(d, dict):\n",
    "            for k in d.keys():\n",
    "                kl = str(k).lower()\n",
    "                if kl in (\"teamstats\", \"teamstatistics\", \"statistics\", \"statrows\", \"teamstatrows\"):\n",
    "                    v = d.get(k)\n",
    "                    if isinstance(v, list) and v and isinstance(v[0], dict):\n",
    "                        candidates.append(v)\n",
    "\n",
    "    if not candidates:\n",
    "        return {}\n",
    "\n",
    "    rows = max(candidates, key=len)  # pick biggest list\n",
    "    feats = {}\n",
    "\n",
    "    for r in rows:\n",
    "        keys = {str(k).lower() for k in r.keys()}\n",
    "        # label key\n",
    "        label = r.get(\"label\") or r.get(\"name\") or r.get(\"stat\") or r.get(\"title\")\n",
    "        if not label:\n",
    "            continue\n",
    "        lab = str(label).strip().lower()\n",
    "        lab = lab.replace(\"%\", \"pct\").replace(\"/\", \"_per_\").replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "        # home/away values keys vary\n",
    "        hv = r.get(\"home\") or r.get(\"homeValue\") or r.get(\"homeStat\") or r.get(\"h\")\n",
    "        av = r.get(\"away\") or r.get(\"awayValue\") or r.get(\"awayStat\") or r.get(\"a\")\n",
    "\n",
    "        # some rows are like {\"values\": {\"home\":..., \"away\":...}}\n",
    "        if hv is None and isinstance(r.get(\"values\"), dict):\n",
    "            hv = r[\"values\"].get(\"home\")\n",
    "            av = r[\"values\"].get(\"away\")\n",
    "\n",
    "        # numeric parse if possible\n",
    "        def to_num(x):\n",
    "            if x is None: \n",
    "                return None\n",
    "            s = str(x).strip().replace(\"%\",\"\")\n",
    "            try:\n",
    "                return float(s)\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        feats[f\"stat_{lab}_home\"] = to_num(hv) if to_num(hv) is not None else hv\n",
    "        feats[f\"stat_{lab}_away\"] = to_num(av) if to_num(av) is not None else av\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "713de01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teams: None vs None\n",
      "n feats: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "mid = 362550\n",
    "props = matchup_pageprops(mid)\n",
    "home, away = extract_home_away_teams(props)\n",
    "print(\"teams:\", home, \"vs\", away)\n",
    "\n",
    "feats = extract_team_stats_features(props)\n",
    "print(\"n feats:\", len(feats))\n",
    "print(list(feats.items())[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1886803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "002aefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage pattern — adjust to the package’s exact API from its README :contentReference[oaicite:10]{index=10}\n",
    "from nbainjuries import injury as inj\n",
    "\n",
    "NOTABLE_PLAYERS = {\n",
    "    # absolute superstars / perennial top-100 (add more over time)\n",
    "    \"LeBron James\",\"Stephen Curry\",\"Kevin Durant\",\"Giannis Antetokounmpo\",\"Nikola Jokic\",\n",
    "    \"Luka Doncic\",\"Joel Embiid\",\"Jayson Tatum\",\"Jimmy Butler\",\"Kawhi Leonard\",\n",
    "    \"Damian Lillard\",\"Anthony Davis\",\"Paul George\",\"Kyrie Irving\",\"James Harden\",\n",
    "    \"Devin Booker\",\"Shai Gilgeous-Alexander\",\"Ja Morant\",\"Trae Young\",\"Donovan Mitchell\"\n",
    "}\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"[^a-z\\s\\-']\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "NOTABLE_NORM = {norm_name(x) for x in NOTABLE_PLAYERS}\n",
    "\n",
    "# inj = injury()\n",
    "\n",
    "def normalize_name(x: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", x.strip())\n",
    "\n",
    "def notable_injury_count_for_game(day: str, home_team: str, away_team: str, injuries_df: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    injuries_df should have columns like: date, team, player, status, etc.\n",
    "    \"\"\"\n",
    "    ht = (home_team or \"\").lower().strip()\n",
    "    at = (away_team or \"\").lower().strip()\n",
    "\n",
    "    df = injuries_df\n",
    "    df = df[df[\"date\"] == day]\n",
    "\n",
    "    # team matching (you may need mapping like \"L.A. Lakers\" -> \"Los Angeles Lakers\")\n",
    "    df = df[df[\"team\"].str.lower().isin([ht, at])]\n",
    "\n",
    "    df[\"player_norm\"] = df[\"player\"].map(norm_name)\n",
    "    df = df[df[\"player_norm\"].isin(NOTABLE_NORM)]\n",
    "\n",
    "    return int(df.shape[0])\n",
    "\n",
    "\n",
    "def notable_injury_count(game_date: str, team_name: str, notable_set: set[str]) -> int:\n",
    "    \"\"\"\n",
    "    game_date: YYYY-MM-DD (local date is fine; injuries are date-based)\n",
    "    team_name: whatever your injury library expects (often full name or abbreviation)\n",
    "    \"\"\"\n",
    "    df = inj.get_reportdata(date=game_date)  # per README usage :contentReference[oaicite:11]{index=11}\n",
    "    if df is None or len(df) == 0:\n",
    "        return 0\n",
    "\n",
    "    # filter team\n",
    "    tdf = df[df[\"team\"].str.lower() == team_name.lower()].copy() if \"team\" in df.columns else df.copy()\n",
    "\n",
    "    # define “injured enough to matter”\n",
    "    status_col = \"status\" if \"status\" in tdf.columns else None\n",
    "    if status_col:\n",
    "        tdf = tdf[tdf[status_col].str.lower().isin({\"out\", \"doubtful\", \"questionable\"})]\n",
    "\n",
    "    cnt = 0\n",
    "    if \"player\" in tdf.columns:\n",
    "        for p in tdf[\"player\"].astype(str):\n",
    "            if normalize_name(p) in notable_set:\n",
    "                cnt += 1\n",
    "    return cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92f232e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-31 matchups: 5 sample: 250647\n",
      "2021-11-01 matchups: 9 sample: 250652\n",
      "2021-11-02 matchups: 5 sample: 250661\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>matchup_id</th>\n",
       "      <th>tipoff_utc</th>\n",
       "      <th>opening_home_spread</th>\n",
       "      <th>closing_line_diff</th>\n",
       "      <th>max_move_for</th>\n",
       "      <th>max_move_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>250647</td>\n",
       "      <td>2021-10-31T19:30:00+00:00</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>250648</td>\n",
       "      <td>2021-10-31T23:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>250649</td>\n",
       "      <td>2021-10-31T23:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>250650</td>\n",
       "      <td>2021-10-31T23:30:00+00:00</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>250651</td>\n",
       "      <td>2021-11-01T02:30:00+00:00</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  matchup_id                 tipoff_utc  opening_home_spread  \\\n",
       "0  2021-10-31      250647  2021-10-31T19:30:00+00:00                 -5.5   \n",
       "1  2021-10-31      250648  2021-10-31T23:00:00+00:00                  1.0   \n",
       "2  2021-10-31      250649  2021-10-31T23:00:00+00:00                  1.0   \n",
       "3  2021-10-31      250650  2021-10-31T23:30:00+00:00                -12.5   \n",
       "4  2021-10-31      250651  2021-11-01T02:30:00+00:00                -12.0   \n",
       "\n",
       "   closing_line_diff  max_move_for  max_move_away  \n",
       "0                1.0           1.5            0.0  \n",
       "1                1.0           1.5            2.0  \n",
       "2                4.0           4.0            0.0  \n",
       "3                0.5           1.0            0.0  \n",
       "4                1.0           1.5            0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def build_rows(start_date: str, end_date: str):\n",
    "    start = dtparser.parse(start_date).date()\n",
    "    end = dtparser.parse(end_date).date()\n",
    "\n",
    "    all_rows = []\n",
    "    d = start\n",
    "    while d <= end:\n",
    "        day = d.isoformat()\n",
    "        mids = matchup_ids_on_date(day)\n",
    "        print(day, \"matchups:\", len(mids), \"sample:\", mids[0] if mids else None)\n",
    "\n",
    "        for mid in mids:\n",
    "            # TODO: parse tipoff time (we can do it next)\n",
    "            # For now, you can still compute peak/valley and later filter pre-tip once we parse tip.\n",
    "            props_lh = parse_fanduel_line_history(mid)     # returns pageProps dict\n",
    "            fd_df = fanduel_spread_history_from_props(props_lh)\n",
    "\n",
    "            tip = tipoff_utc_from_matchup(mid)\n",
    "\n",
    "            opening, closing_diff, max_for, max_away = compute_targets_from_fd_history(fd_df, tip)\n",
    "\n",
    "            props_match = matchup_pageprops(mid)\n",
    "            home_team, away_team = extract_home_away_teams(props_match)\n",
    "            team_feats = extract_team_stats_features(props_match)\n",
    "\n",
    "            # num_notable_inj = notable_injury_count(...)  # using normalized names + team mapping\n",
    "\n",
    "            # if opening is None:\n",
    "            #     skip[\"targets\"] += 1\n",
    "            #     continue\n",
    "\n",
    "            row = {\n",
    "                \"date\": day,\n",
    "                \"matchup_id\": mid,\n",
    "                \"tipoff_utc\": tip.isoformat(),\n",
    "                \"opening_home_spread\": opening,\n",
    "                \"closing_line_diff\": closing_diff,\n",
    "                \"max_move_for\": max_for,\n",
    "                \"max_move_away\": max_away,\n",
    "            }\n",
    "\n",
    "            all_rows.append(row)\n",
    "\n",
    "        d = d + timedelta(days=1)\n",
    "\n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "\n",
    "\n",
    "df = build_rows(\"2021-10-31\", \"2021-11-02\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c971e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=1 R2=-7.2250\n",
      "fold=2 R2=-0.2452\n",
      "fold=3 R2=-26.6205\n",
      "fold=4 R2=-0.2959\n",
      "fold=5 R2=-0.2160\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "target_cols = [\"closing_line_diff\", \"max_move_for\", \"max_move_away\"]\n",
    "y = df[target_cols]\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in target_cols and c not in [\"date\", \"eid\", \"tipoff_utc\", \"home_team\", \"away_team\"]]\n",
    "X = df[feature_cols]\n",
    "\n",
    "numeric = feature_cols\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "model = MultiOutputRegressor(Ridge(alpha=1.0))\n",
    "\n",
    "pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "# time series split (by date order)\n",
    "df_sorted = df.sort_values([\"date\", \"tipoff_utc\"]).reset_index(drop=True)\n",
    "X_sorted = df_sorted[feature_cols]\n",
    "y_sorted = df_sorted[target_cols]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (tr, te) in enumerate(tscv.split(X_sorted), 1):\n",
    "    pipe.fit(X_sorted.iloc[tr], y_sorted.iloc[tr])\n",
    "    score = pipe.score(X_sorted.iloc[te], y_sorted.iloc[te])  # R^2 (multioutput averaged)\n",
    "    print(f\"fold={fold} R2={score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
